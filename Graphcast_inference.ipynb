{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Graphcast:**\n",
        "\n",
        "This repository tries to mimic the inference step for encoder and processor of Google deepmind's Graphcast paper. Input features for nodes and edges for grids and meshes are randomly initialized for simplicity."
      ],
      "metadata": {
        "id": "RiQDydemZcF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "configure() function has not been used to input variable sizes. Instead the variables are provided in following section. The paper has their values (for example 103200). For running the code in colab without runtime issues, I divided those values using 10^4 (for example, modified value is 10).\n",
        "\n",
        "e.g.,\n",
        "real value: 103200,\n",
        "modified value : 10 #320"
      ],
      "metadata": {
        "id": "cAAQ8_0FYh9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "### All values defined in the paper (Following section 3.3,  Pg 26 and beyond)\n",
        "'''V(G):At 0.25¬∞ resolution, there is a total of 721 √ó 1440 = 1, 038, 240 grid nodes, each with (5 surface variables + 6 atmospheric variables\n",
        "√ó 37 levels) √ó 2 steps + 5 forcings √ó 3 steps + 5 constant = 474 input features.'''\n",
        "grid_nodes = 103  #8240\n",
        "grid_node_features = 474\n",
        "\n",
        "\n",
        "'''v(M): features associated with each mesh node include the cosine of the latitude, and the sine and cosine of the longitude. '''\n",
        "mesh_nodes = 40  #962\n",
        "mesh_node_features = 3\n",
        "\n",
        "'''e(M):For each edge ùëí(s ‚Üíùë£) connecting a sender mesh node ùë£ to a receiver mesh node ùë£, we build\n",
        "edge features using the position on the unit sphere of the mesh nodes. This includes the\n",
        "length of the edge, and the vector difference between the 3d positions of the sender node and the\n",
        "receiver node computed in a local coordinate system of the receiver....\n",
        "total of 327,660 mesh edges (See Table 4), each with 4 input features.'''\n",
        "mesh_edges = 32  #7660\n",
        "mesh_edge_features = 4\n",
        "\n",
        "'''e(G->M): unidirectional edges that connect sender grid nodes to receiver mesh nodes.\n",
        " Features are built the same way as those for the mesh edges. This results on a total of 1,618,746 Grid2Mesh edges, each with 4 input features.'''\n",
        "grid2mesh_edge = 161  #8746\n",
        "grid2mesh_edge_features = 4\n",
        "\n",
        "\n",
        "mesh2grid_edge = 311  #4720\n",
        "mesh2grid_edge_features = 4\n",
        "\n",
        "\n",
        "'''embedding dim is not specified particularly in the paper, but hidden and o/p dim are given as 512.\n",
        " So mathematically embedded_feature_latent dim has to be 512'''\n",
        "grid_hidden_dim = 512\n",
        "mesh_hidden_dim = 512\n",
        "edge_hidden_dim = 512\n",
        "embed_feature_latent_dim = 512\n",
        "\n",
        "processor_num_layers = 16"
      ],
      "metadata": {
        "id": "poLAKaCCZO_e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " As only inference steps are mimicked, we have not trained MLP weights. However, even for inference, we need the trained weights for the MLPs. So we initialized these weights :randomly."
      ],
      "metadata": {
        "id": "araA0dNHaAJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Standard MLP for embedding\n",
        "''' instead of ‚Äúswish‚Äù activation function, used RELU for all MLPs '''\n",
        "''' hidden layer and output layer has same dimension (512) for encoder and processor'''\n",
        "''' weights of these MLP are randomly initialized and used for single pass'''\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(output_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "bBmRx7cqZH4q"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # Define MLPs for each feature type\n",
        "        self.mlp_grid_node = MLP(grid_node_features, embed_feature_latent_dim)\n",
        "        self.mlp_mesh_node = MLP(mesh_node_features, embed_feature_latent_dim)\n",
        "        self.mlp_mesh_edge = MLP(mesh_edge_features, embed_feature_latent_dim)\n",
        "        self.mlp_g2m_edge = MLP(grid2mesh_edge_features, embed_feature_latent_dim)\n",
        "        self.mlp_m2g_edge = MLP(mesh2grid_edge_features, embed_feature_latent_dim)\n",
        "\n",
        "    def forward(self, vg, vm, em, eg2m, em2g):\n",
        "        # Embedding the features for all nodes and edges\n",
        "        vg_embedded = self.mlp_grid_node(vg)\n",
        "        vm_embedded = self.mlp_mesh_node(vm)\n",
        "        em_embedded = self.mlp_mesh_edge(em)\n",
        "        eg2m_embedded = self.mlp_g2m_edge(eg2m)\n",
        "        em2g_embedded = self.mlp_m2g_edge(em2g)\n",
        "\n",
        "        return vg_embedded, vm_embedded, em_embedded, eg2m_embedded, em2g_embedded\n"
      ],
      "metadata": {
        "id": "I-spLFweZHFd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Grid2MeshGNN module\n",
        "class Grid2MeshGNN(nn.Module):\n",
        "    def __init__(self, embed_feature_latent_dim, grid_hidden_dim, mesh_hidden_dim, edge_hidden_dim):\n",
        "        super(Grid2MeshGNN, self).__init__()\n",
        "        # MLP for updating grid-to-mesh edge features which takes concatenated features of a grid node, a mesh node, and the edge as input\n",
        "        ## This is used as a substitute for a GNN library for simplicity\n",
        "        self.edge_update_mlp = MLP(embed_feature_latent_dim *3, edge_hidden_dim)\n",
        "\n",
        "        # MLP for updating mesh node features which processes the aggregated edge features and the original mesh nodefeatures\n",
        "        ## This is also used as a substitute for a GNN library for simplicity as above\n",
        "        self.mesh_node_update_mlp = MLP(embed_feature_latent_dim+mesh_hidden_dim, mesh_hidden_dim)\n",
        "\n",
        "        # MLP for updating grid node features (aggregation not added)\n",
        "        self.grid_node_update_mlp = MLP(embed_feature_latent_dim, grid_hidden_dim)\n",
        "\n",
        "    def forward(self, vg_embed, vm_embed, eg2m_embed, edge_indices):\n",
        "\n",
        "        # Obtain features for source nodes (grid nodes) using the first row of edge_indices\n",
        "        src_features = vg_embed[edge_indices[0, :]]\n",
        "\n",
        "        # Obtain features for destination nodes (mesh nodes) using the second row of edge_indices\n",
        "        dst_features = vm_embed[edge_indices[1, :]]\n",
        "\n",
        "        # Concatenate source node features, destination node features, and edge features for each edge\n",
        "        edge_features = torch.cat((src_features, dst_features, eg2m_embed), dim=1)\n",
        "\n",
        "\n",
        "        # Update edge features using the defined MLP\n",
        "        eg2m_embed_updated = self.edge_update_mlp(edge_features)\n",
        "\n",
        "\n",
        "        ### ToDo: This part needs to be replaced by GNN libraries\n",
        "\n",
        "        # Initialize a tensor to accumulate aggregated features for each mesh node\n",
        "        vm_embed_aggregated = torch.zeros(vm_embed.shape[0],eg2m_embed_updated.shape[1])\n",
        "\n",
        "        # Iterate over each edge to aggregate the updated edge features to the corresponding destination node\n",
        "        for i, dst_idx in enumerate(edge_indices[1, :]):\n",
        "            vm_embed_aggregated[dst_idx] += eg2m_embed_updated[i]\n",
        "\n",
        "        # Update mesh node features by combining original features with aggregated edge features using MLP\n",
        "        vm_embed_updated = self.mesh_node_update_mlp(torch.cat((vm_embed, vm_embed_aggregated), dim=1))\n",
        "\n",
        "        # Update grid nodes\n",
        "        # Directly update grid node features using the MLP defined\n",
        "        vg_embed_updated = self.grid_node_update_mlp(vg_embed)\n",
        "\n",
        "        ##### Apply residual connections to all nodes and edges\n",
        "        # Addding the original features to the updated features for grid nodes, mesh nodes, and edges\n",
        "        vg_embed_final = vg_embed + vg_embed_updated  # Final grid node features\n",
        "        vm_embed_final = vm_embed + vm_embed_updated  # Final mesh node features\n",
        "        eg2m_embed_final = eg2m_embed + eg2m_embed_updated  # Final edge features\n",
        "\n",
        "        return vg_embed_final, vm_embed_final, eg2m_embed_final"
      ],
      "metadata": {
        "id": "k8FUfabJZVBc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the message passing using modified version of adjancency matrix\n",
        "  ## the modified adjacency matrix's row indices are mesh_node indices and column indices are mesh_edge indices\n",
        "  ## summed feature of neighbouring edges for all mesh_nodes=adj_matrix * mesh_edge feature matrix\n",
        "class message_pass(nn.Module):\n",
        "  def __init__(self,mesh_nodes,mesh_edges):\n",
        "    super(message_pass,self).__init__()\n",
        "    self.adj_mat=torch.randint(high=2, size=(mesh_nodes, mesh_edges)).float()\n",
        "    print(\"matrix for message passing:Row(Node) * Column(Edge)=\",self.adj_mat)\n",
        "    print(\"message passing matrix has shape=\",self.adj_mat.shape)\n",
        "  def forward(self,em_updated,vm_updated):\n",
        "    edge_sum= torch.matmul(self.adj_mat,em_updated)\n",
        "    vm_processor=torch.cat((vm_updated,edge_sum),dim=1)\n",
        "    return vm_processor"
      ],
      "metadata": {
        "id": "oMb7Bwh9hkWN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Encoder oparations:***"
      ],
      "metadata": {
        "id": "xcioBPr0YK9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dummy features\n",
        "vg = torch.randn(grid_nodes, grid_node_features)\n",
        "vm = torch.randn(mesh_nodes, mesh_node_features)\n",
        "\n",
        "# For mesh edges, assuming a simple source-target format for the edges, with random features\n",
        "em = torch.randn(mesh_edges, mesh_edge_features)\n",
        "\n",
        "# For grid to mesh and mesh to grid edges, initializing edge features\n",
        "eg2m = torch.randn(grid2mesh_edge, grid2mesh_edge_features)\n",
        "em2g = torch.randn(mesh2grid_edge, mesh2grid_edge_features)\n",
        "\n",
        "#Encoder operations:\n",
        "\n",
        "encoder = Encoder()\n",
        "\n",
        "## One dummy forward pass through Encoder\n",
        "vg_embedded, vm_embedded, em_embedded, eg2m_embedded, em2g_embedded = encoder(vg, vm, em, eg2m, em2g)\n",
        "\n",
        "# Output shapes from Encoder\n",
        "print(\"vg_embedded shape:\", vg_embedded.shape)\n",
        "print(\"vm_embedded shape:\", vm_embedded.shape)\n",
        "print(\"em_embedded shape:\", em_embedded.shape)\n",
        "print(\"eg2m_embedded shape:\", eg2m_embedded.shape)\n",
        "print(\"em2g_embedded shape:\", em2g_embedded.shape)\n",
        "\n",
        "\n",
        "\n",
        "# Assuming edge_indices is a tensor indicating the connections from grid nodes to mesh nodes\n",
        "# For simplicity, randomly generated indices are used\n",
        "\n",
        "## Since it is a bipartite graph from grid nodes to edge nodes, first column is the source node (grid) and the second column is the destination node(mesh)\n",
        "edge_grid_source = torch.randint(0, grid_nodes, (1, grid2mesh_edge), dtype=torch.long)\n",
        "edge_mesh_dst = torch.randint(0, mesh_nodes, (1, grid2mesh_edge), dtype=torch.long)\n",
        "\n",
        "## Final concatenated bipartite graph\n",
        "edge_indices_g2m = torch.cat((edge_grid_source, edge_mesh_dst), dim=0)\n",
        "\n",
        "\n",
        "# Instantiate the Grid2MeshGNN model\n",
        "grid2mesh_gnn = Grid2MeshGNN(embed_feature_latent_dim,grid_hidden_dim, mesh_hidden_dim, edge_hidden_dim)\n",
        "\n",
        "# Use outputs from Encoder and perform forward pass through the GNN to Update features using the Grid2MeshGNN\n",
        "vg_updated, vm_updated, eg2m_updated = grid2mesh_gnn(vg_embedded, vm_embedded, eg2m_embedded, edge_indices_g2m)\n",
        "\n",
        "print(f\"Updated Grid Node Features Shape: {vg_updated.shape}\")\n",
        "print(f\"Updated Mesh Node Features Shape: {vm_updated.shape}\")\n",
        "print(f\"Updated Grid2Mesh Edge Features Shape: {eg2m_updated.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za0iof6XZbzx",
        "outputId": "1ffef5a1-8a63-4e22-a40a-568434376aa3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vg_embedded shape: torch.Size([103, 512])\n",
            "vm_embedded shape: torch.Size([40, 512])\n",
            "em_embedded shape: torch.Size([32, 512])\n",
            "eg2m_embedded shape: torch.Size([161, 512])\n",
            "em2g_embedded shape: torch.Size([311, 512])\n",
            "Updated Grid Node Features Shape: torch.Size([103, 512])\n",
            "Updated Mesh Node Features Shape: torch.Size([40, 512])\n",
            "Updated Grid2Mesh Edge Features Shape: torch.Size([161, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Processor:***"
      ],
      "metadata": {
        "id": "HVnkUJ35Xrt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Message passing should have 6 loops- starting from M^6 to M^0\n",
        "* For each M^R: mesh node features are updated using neighbouring edge features.\n",
        "* The list of neighbours for each M^R are different. For example, neighbour of a node in M^6 icosahedron mesh are:{1,2,3,4,5}, but neighbour of that node in M^5 icosahedron mesh are:{6,7,8,9,10}. Also, nodes:{6,7,8,9,10} are more distant than nodes:{1,2,3,4,5} from the concerned node.\n",
        "* Creation of this neighbour list for each M^R icosahedron based mesh, requires information about (x,y,z) coordinates of those mesh nodes.These, (x,y,z) mesh node coordinate values should be calculated using M^R icosahedron mesh edge length and angle between edges of that icosahedron.\n",
        "\n",
        "* **I have skipped these calculations for brevity of the code. Also, I consider that, I have just 1 mesh, so the following operations are performed once and not in loops. Information of neighbours of a node are not generated using geometry of icosahedron. Instead they are randomly generated**."
      ],
      "metadata": {
        "id": "aC-eXBtoUCxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a torch tensor containing infor about source and destination mesh node number for all mesh edges\n",
        "  ## position of each column of tensor: index of mesh edge\n",
        "  ## first row of the torch tensor: index of source mesh node\n",
        "  ## second row of the torch tensor: index of destination mesh node\n",
        "mesh_edge_indices = torch.randint(high=mesh_nodes, size=(2, mesh_edges))\n",
        "\n",
        "\n",
        "#updates each of the mesh edges using information of the adjacent mesh nodes\n",
        "vm_source=vm_updated[mesh_edge_indices[0, :]]\n",
        "vm_dst=vm_updated[mesh_edge_indices[1, :]]\n",
        "\n",
        "em_processor=torch.cat((em_embedded,vm_source,vm_dst),dim=1)\n",
        "input_shape=em_processor.shape[1]\n",
        "\n",
        "em_MLP=MLP(input_shape,mesh_hidden_dim)\n",
        "em_updated=em_MLP(em_processor)\n",
        "\n",
        "#updates each of the mesh nodes, aggregating information from all of the edges arriving at that mesh node\n",
        "GNN_part1=message_pass(mesh_nodes,mesh_edges)\n",
        "vm_changed = GNN_part1(em_updated, vm_updated)\n",
        "\n",
        "in_shape=vm_changed.shape[1]\n",
        "GNN_part2=MLP(in_shape,mesh_hidden_dim)\n",
        "vm_new=GNN_part2(vm_changed)\n",
        "\n",
        "# the representations are updated with a residual connection\n",
        "vm_final=vm_updated+vm_new\n",
        "em_final=em_updated+em_updated\n",
        "\n",
        "print(\"After processor, mesh node shape =\",vm_final.shape)\n",
        "print(\"After processor, mesh edge shape =\",em_final.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdsg_2a8FZp4",
        "outputId": "21a1318f-83fb-482d-a30d-ac34ae758652"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrix for message passing:Row(Node) * Column(Edge)= tensor([[1., 0., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [1., 1., 0.,  ..., 1., 1., 1.],\n",
            "        ...,\n",
            "        [1., 0., 1.,  ..., 0., 1., 1.],\n",
            "        [0., 0., 1.,  ..., 1., 1., 1.],\n",
            "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
            "message passing matrix has shape= torch.Size([40, 32])\n",
            "After processor, mesh node shape = torch.Size([40, 512])\n",
            "After processor, mesh edge shape = torch.Size([32, 512])\n"
          ]
        }
      ]
    }
  ]
}